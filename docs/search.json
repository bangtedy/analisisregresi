[{"path":"index.html","id":"kata-pengantar","chapter":"Kata Pengantar","heading":"Kata Pengantar","text":"Manusia sering punya rasa ingin tahu tentang bagaimana suatu hal berkaitan dengan hal yang lain. Dengan kata lain, kita sebagai manusia seringkali tertarik melihat hubungan antara sebuah variabel dengan variabel lain. Di dunia akademik maupun praktik, salah satu alat yang bisa dipakai untuk mempelajari kaitan antar variabel adalah analisis regresi.Aplikasi pengetahuan tentang hubungan antar variabel dapat dipakai untuk membuat prediksi dan skenario : bagaimana sebuah variabel akan berubah jika terjadi perubahan pada variabel lain yang berkaitan. Prediksi dan skenario menguji pemahaman kita tentang hubungan antar variabel. Jika kita tidak tepat memahami hubungan antar variabel ini, prediksi dan skenario yang kita buat bisa tidak tepat juga.Analisis regresi sejatinya menganalisis hubungan antar variabel. Dengan bantuan komputer dan pemikiran yang cermat, analisis regresi dapat menjadi alat untuk membedah data yang kompleks. Tetapi, komputer tidak bisa berpikir dan merencanakan sendiri. Komputer hanya membantu peneliti melakukan perhitungan secara cepat, agar peneliti memiliki lebih banyak waktu untuk berpikir dan memperbaiki model analisisnya.Di dalam buku singkat ini, saya akan membahas analisis regresi dan penerapannya. Pembahasan dimulai dengan regresi linier sederhana, kemudian dilanjutkan ke pembahasan regresi berganda. Program yang akan digunakan adalah R (R Core Team 2021) yang bisa diunduh secara gratis di sini.Tetapi buku ini bukan buku tentang R. Juga bukan buku tentang statistik. Materi untuk belajar R sangat banyak tersedia secara online misalnya Introduction R. Pembaca juga bisa mengikuti berbagai topik di R-bloggers. Tujuan buku ini adalah untuk memperkuat pemahaman pembaca tentang model regresi sebagai salah satu alat analisis yang bisa diterapkan pada berbagai bidang akademik maupun praktik. Saya mengharapkan buku ini bisa menjadi live book yang berkembang sesuai saran pembaca.Catatan: Analisis Regresi: Disertai Contoh-Contoh Menggunakan R hak cipta ada pada Tedy Herlambang dan diedarkan berdasarkan Creative Commons -NC-ND 4.0 International License. Anda bebas menggunakan isi buku ini untuk tujuan non-komersial, dengan menyebutkan sumbernya ke https://bangtedy.github.io/analisisregresi.Cara mengutip:Herlambang, Tedy. 2022. Analisis Regresi. URL https://bangtedy.github.io/analisisregresi.","code":""},{"path":"index.html","id":"disclaimer","chapter":"Kata Pengantar","heading":"Disclaimer","text":"information book provided without warranty. authors publisher neither liability responsibility person entity related loss damages arising information contained book.Terakhir diperbarui pada: 08 January 2022.","code":""},{"path":"pendahuluan.html","id":"pendahuluan","chapter":"1 Pendahuluan","heading":"1 Pendahuluan","text":"Sebagai praktisi atau akademisi, terkadang kita tertarik untuk\nmeningkatkan pemahaman atas sesuatu dengan menginvestigasinya. Tertulis\natau hanya tercatat di dalam pikiran, di dalam proses investigasi ini,\nkita menyusun hipotesis-hipotesis yang ingin kita buktikan kebenarannya.Untuk sampai pada kesimpulan menolak atau menerima hipotesis-hipotesis\nini, kita merancang investigasinya, mengumpulkan data/bukti-bukti\nkemudian menganalisisnya. Di dalam analisis data, seorang investigator\nberhadapan dengan data yang berasal dari suatu populasi. Hasil analisis\ndapat menyediakan bukti-bukti statistik yang mendukung atau menolak\nhipotesis yang telah kita buat.Proses investigasi ini biasanya iteratif, tidak sekali luncur langsung\nselesai. Dalam beberapa hal, investigasi harus kita ulang lagi sampai\ndidapatkan sebuah model statistik yang memuaskan dengan mempertimbangkan\nkepraktisan, biaya dan waktu yang tersedia. Model statistik ini\nmenampilkan karakteristik-karakteristik penting dari populasi dimana\ndata yang dianalisis berasal.Subjek investigasi atau percobaan kita dapat berupa hal-hal yang berada\ndi dalam atau di luar diri kita, yang kasatmata atau tidak. Aerobiologi\nmempelajari partikel-partikel organik (bakteri, spora jamur, polen,\nserangga-serangga kecil) yang terbawa udara secara pasif. Astronomi\nmempelajari benda langit dan fenomena-fenomena alam yang terjadi di luar\natmosfer bumi. Ilmu Ekonomi mempelajari kegiatan produksi, alokasi dan\ndistribusi barang dan jasa. Psikologi mempelajari alam pikiran manusia.\nGeologi mempelajari bentuk dan komposisi bumi.Analisis regresi tidak mempelajari suatu subjek secara langsung tetapi\nsebagai alat analisis yang dipakai di sebuah bidang ilmu. Kegunaannya\ntidak langsung tetapi melalui bantuan yang diberikan ke bidang ilmu\nlain.Analisis regresi sangat berguna, sebab hampir semua cabang ilmu\npengetahuan harus berhubungan dengan data yang tidak sempurna.\nKetidaksempurnaan data ini mungkin terjadi karena kita hanya dapat\nmengamati dan mencatat sebagian saja dari apa yang relevan dengan subjek\npenelitian kita.Atau bisa juga karena kita hanya dapat mengamati secara tidak langsung\ndari apa yang benar-benar relevan dengan subjek yang diamati. Mungkin\njuga karena seberapapun hati-hati kita melakukan observasi atau\nmendesain sebuah percobaan, data yang diperoleh akan selalu mengandung\nunsur ‘gangguan’ (noise).Menurut (Agresti 2015), (Frees 2010) dan (Lee, Lee, Lee 2013) analisis regresi\nadalah salah satu teknik statistik yang paling luas dipakai.\nPenerapannya meliputi hampir semua bidang ilmu: bisnis, ekonomi, teknik,\nilmu-ilmu sosial, biologi dan kesehatan. Pada beberapa proyek penelitian\nanalisis regresi bahkan seringkali menjadi alat analisis utamanya.\nKeberhasilan penerapan model regresi linier memerlukan pemahaman baik\nakan teori yang mendasarinya maupun persoalan-persoalan praktis yang\nsering terjadi di dalam penggunaan alat analisis ini dalam situasi riil.","code":""},{"path":"pendahuluan.html","id":"model-regresi-linier","chapter":"1 Pendahuluan","heading":"1.1 Model Regresi Linier","text":"Model di dalam analisis regresi merujuk pada ekspresi matematik yang\nmenjelaskan perilaku-perilaku dari variabel-variabel yang menjadi\nperhatian. Model regresi linier atau biasa disebut analisis regresi\n(Faraway 2015) digunakan untuk menjelaskan atau memodelkan hubungan\nantara satu variabel respons \\(y\\) dengan satu atau lebih variabel\nprediktor \\(x_1, x_2, ... , x_p\\), dimana \\(p\\) adalah jumlah prediktor.\nSecara khusus, analisis regresi adalah upaya untuk menjelaskan\npergerakan sebuah variabel respons dengan merujuk pada pergerakan satu\natau lebih variabel eksplanatori. Jika \\(p=1\\), modelnya disebut regresi\nsederhana. Tetapi jika \\(p>1\\), disebut regresi berganda.Dalam analisis regresi, kita dapat menggunakan pengetahuan tentang\nhubungan ini untuk memprediksi respons variabel \\(y\\) melalui variabel\n\\(x\\). Karena hubungan inilah maka \\(y\\) disebut variabel respons dan \\(x\\)\ndisebut variabel prediktor. Beberapa rumpum ilmu berbeda menggunakan\nistilah yang berbeda untuk menyebut variabel \\(x\\) dan \\(y\\).Beberapa penyebutan untuk variabel \\(x\\) dan \\(y\\) ditunjukkan pada Tabel\n1.1. Di dalam ekonometrika seringkali digunakan istilah variabel\ndependen dan variabel independen. Di bidang ilmu yang berhubungan dengan\neksperimen biasanya digunakan istilah variabel respons dan variabel\nkontrol karena variabel \\(x\\) berada dibawah kendali peneliti. Dibuku ini\npenyebutan-penyebutan itu akan digunakan secara bebas.\nTabel 1.1: Beberapa Penyebutan Variabel dalam Analisis Regresi\nJika memungkinkan, di dalam analisis regresi kita juga ingin\nmenyimpulkan apakah terdapat hubungan sebab-akibat: mengetahui pengaruh\ndari variabel prediktor terhadap variabel respons.Beberapa contohnya misalnya:Hubungan antara ukuran kelas/jumlah siswa per kelas dengan rata-rata\nnilai pelajaran Bahasa Daerah di sebuah SMA. Disini \\(y\\) adalah\nrata-rata nilai pelajaran Bahasa Daerah dan \\(x\\) adalah jumlah siswa\nper kelas.Hubungan antara tingkat pendapatan seseorang (\\(y\\)) dengan pendidikan\nterakhir yang ditamatkannya (\\(x\\)).Kinerja karyawan dapat diprediksi dengan menggunakan hubungan antara\nkinerja (\\(y\\)) dan hasil tes aptitutenya (\\(x\\)).Apakah terdapat hubungan antara tingkat kelahiran penduduk suatu\nnegara dengan tingkat pendapatan perkapitanya? Jika diperhatikan\nnegara-negara dengan tingkat pendapatan per kapita tinggi (\\(x\\)),\ntingkat pertumbuhan penduduknya rendah (\\(y\\)), dan sebaliknya.Jumlah kosakata seorang anak dapat diprediksi dengan menggunakan\npengetahuan hubungan antara jumlah kosa kata (\\(y\\)), usia anak\n(\\(x_1\\)) dan tingkat pendidikan orang tua si anak (\\(x_2\\)).Hubungan antara desain pekerjaan (\\(x\\)) dengan perilaku karyawan di\nsebuah perusahaan (\\(y\\)). Perusahaan menginginkan agar karyawan\nberaktivitas dan berinteraksi secara efektif sehingga pekerjaan\nharus didesain dengan baik sehingga menghasilkan perilaku positif\ndan komitmen tinggi karyawan terhadap pekerjaannya. Walaupun inti\ninvestigasi ini adalah analisis regresi, tetapi di dalam contoh ini,\nkita berhubungan dengan konsep-konsep abstrak/konstruk-konstruk yang\nmemerlukan alat analisis sendiri seperti analisis faktor. Topik ini\ndibahas di buku saya yang lain tentang analisis\nfaktor.Sebagai ilustrasi, kita akan menggunakan kasus hubungan antara tingkat\npenjualan sepeda motor dengan pertumbuhan pendapatan per kapita di\nIndonesia dalam 20 tahun terakhir. Motor sebagai salah satu moda\ntransportasi sangat populer di Indonesia karena berbagai alasan: praktis\ndan terjangkau. Penjualan motor berhubungan dengan tingkat pendapatan,\nharga motor, ketersediaan moda transportasi alternatif, selera, dll. Di\nkasus ini kita hanya mengambil pendapatan sebagai variabel eksplanatori.Tabel 1.2 menunjukkan data dalam kasus ini. Data penjualan motor (\\(y\\))\ndiperoleh dari AISI, sedangkan data\npendapatan didekati dengan pertumbuhan pendapatan per kapita (\\(x\\)) yang\ndiperoleh dari World Bank.\nSatuan \\(y\\) dalam juta unit, sedangkan \\(x\\) dalam persen. Secara teoritis\nterdapat hubungan positif antara tingkat pendapatan dengan penjualan\nmotor karena motor adalah barang normal.\nTabel 1.2: Penjualan Motor (y) dan Pertumbuhan Pendapatan (x) 2001-2019\nLangkah awal untuk melihat apakah data yang kita miliki memang mengandung “sinyal” yang menunjukkan hubungan antara pendapatan dengan penjualan motor adalah membuat diagram pencar (scatter plot). Diagram pencar bisa menunjukkan secara kasar apakah hubungan antar variabel dapat dianggap linier atau tidak. Gambar 1.1 menunjukkan bahwa hubungan linier antara penjualan motor dengan pendapatan tidak cukup meyakinkan. Tetapi kita coba menarik garis lurus yang paling banyak “mendekati” titik-titik data pengamatan yang tersebar.\nGambar 1.1: Diagram Pencar\nGambar 1.1 menunjukkan bahwa memang terdapat sinyal yang sesuai dengan asumsi yaitu penjualan motor proporsional dengan pertumbuhan pendapatan per kapita: semakin tinggi pertumbuhan pendapatan per kapita semakin tinggi pula tingkat penjualan motor. Tetapi setelah kita tarik garis lurus (Gambar 1.2) proporsionalitas ini tidak ketat. Garis lurus yang kita buat tidak menyinggung seluruh data yang tersebar atau data sampel tidak bisa seluruhnya tepat berada pada garis yang dibuat.Titik-titik pengamatan ada yang tepat digaris, ada juga yang di\natas atau di bawah garis. Hal ini menunjukkan adanya variasi pada\npenjualan motor yang tidak berhubungan dengan tingkat pendapatan. Dengan\nkata lain terdapat faktor-faktor lain selain pendapatan yang juga\nmempengaruhi tingkat penjualan tetapi tidak kita masukkan ke dalam\nmodel.\nGambar 1.2: Diagram Pencar dan Estimasi Garis Linier\nBagaimana kita akan memodelkan faktor-faktor lain ini? Untuk\nmenjawabnya, kita mulai dulu dengan memodelkan hubungan antara \\(y\\) dan\n\\(x\\) dengan sebuah persamaan garis linier (garis biru):\\[\\begin{equation} \ny_i=\\beta_0 + \\beta_1x_i\n\\tag{1.1}\n\\end{equation}\\]Persamaan ini menyatakan bahwa \\(y\\) sebagai variabel respons adalah\nfungsi linier \\(x\\), variabel prediktor. \\(\\beta_0\\) adalah konstanta yang\nmenunjukkan nilai dari \\(y\\) jika \\(x\\) sama dengan nol. \\(\\beta_1\\) adalah\nkoefisien kemiringan garis yang menunjukkan berapa banyak \\(y\\) akan\nberubah jika \\(x\\) meningkat sebanyak satu unit.Faktor lain selain pendapatan yang menyebabkan variasi pada penjualan\nmotor kita masukkan sebagai faktor acak. Faktor acak ini secara visual\nditunjukkan oleh panjang garis vertikal (warna merah putus-putus)\nantara titik data pengamatan (lingkaran putih kecil) dengan garis\nregresi atau nilai dugaan variabel respons (garis biru).Faktor acak/error ini menunjukkan adanya variasi pada penjualan yang\ntidak dapat dijelaskan oleh model dan disimbolkan dengan \\(\\epsilon\\).\nMaka persamaan diatas dapat kita tuliskan lagi sebagai:\\[\\begin{equation} \ny_i=\\beta_0 + \\beta_1x_i + \\epsilon_i\n\\tag{1.2}\n\\end{equation}\\]\\(\\epsilon_i\\) dimasukkan ke dalam persamaan untuk mengakomodasi faktor\nerror dan variasi dalam \\(y\\) yang tidak dapat dijelaskan oleh variabel\n\\(x\\).Di dalam konteks ini error bukan berarti kesalahan, melainkan istilah\nstatistik yang mewakili fluktuasi acak, kesalahan pengukuran, atau\ndampak dari faktor-faktor diluar kendali peneliti (Faraway 2016). Jadi\n\\(\\epsilon\\) ini mewakili ketidakmampuan model untuk menjelaskan variasi\nyang terjadi pada variabel respons.Setiap model pasti mengandung error, karena hubungan statistik tidak\nmemiliki ketepatan seperti halnya fungsi matematika. Jadi ketika kita\nmencoba menjelaskan variabel \\(y\\) dengan menggunakan variabel \\(x\\) ini,\nkita menggunakan hubungan statistik: sebuah hubungan yang tidak eksak.Bahkan, seandainya variabel-variabel lain ditambahkan ke dalam model,\ntetap akan ada variasi di dalam y yang tidak dapat dijelaskan oleh\nmodel. Variasi ini bisa karena bentuk fungsional yang tidak benar atau\nbisa juga karena semata-mata faktor kejadian yang tidak dapat\ndiprediksi.Tujuan utama kita dalam analisis regresi adalah mendapatkan nilai dugaan\n\\(\\hat \\beta_0\\) dan \\(\\hat \\beta_1\\) terbaik sehingga jarak vertikal untuk\nsetiap titik data pengamatan dan nilai dugaannya secara kolektif paling\nkecil. Dengan kata lain kita ingin menarik garis dalam bidang x−y\nsedekat mungkin dengan persebaran titik-titik data sampel yang telah\nkita kumpulkan.Garis yang menghubungkan variabel-variabel dapat kita buat secara manual\nsehingga didapatkan nilai dugaan \\(\\hat \\beta_0\\) dan \\(\\hat \\beta_1\\).\nTetapi dalam praktik cara ini tentu saja kurang akurat. Oleh karena itu,\nkita akan mengestimasi garis ini dan menunjukkan hubungan antar variabel\nini dalam sebuah persamaan melalui suatu prosedur formal yang disebut\nmetode kuadrat terkecil/ordinary least squares (OLS).Persamaan ini disebut sebagai garis regresi, dituliskan sebagai\n\\(\\hat y_i = \\hat \\beta_0 + \\hat \\beta_1x_i\\). Metode OLS menghitung\nmasing-masing jarak vertikal antara data pengamatan dengan garis dugaan\n(error dari data sampel), mengkuadratkannya dan mencari yang jumlah\ntotalnya paling kecil.Sebuah model regresi linier yang sudah dikalibrasi paling pas dengan\ndata sampel (best fit), dapat digunakan untuk menjelaskan hubungan\natau membuat prediksi dengan mencermati perbedaan (arah) dan intensitas\nperubahan (magnitud) dari variabel \\(y\\) pada nilai variabel \\(x\\) tertentu.Analisis regresi menawarkan pendekatan yang masuk akal dengan mengenali\npola-pola hubungan antar variabel: arah dan besar perubahan pada\nvariabel respons dengan arah dan besar perubahan pada variabel prediktor\ndari model yang valid.Dengan demikian persamaan regresi yang memodelkan hubungan statistik\nantar variabel terdiri dari dua komponen: komponen deterministik atau\nsinyal yaitu \\(\\beta_0 + \\beta_1\\) dan komponen acak atau gangguan (*noise)yaitu \\(\\epsilon\\). Kombinasi kedua komponen ini menjadikan\npersamaan regresi sebagai model non-eksak, yaitu bergantung pada bentuk-bentuk penjelasan probabilistik. Kita hanya mengasumsikan bahwa di dalam cakupan variabel yang dianalisis, terdapat tendensi variabel respons \\(y\\) untuk bervariasi secara sistematis dengan\nvariabel prediktor \\(x\\). Komponen acak ditambahkan ke dalam model untuk mengakomodasi variasi di residu.Mayoritas analisis regresi yang baku menggunakan model regresi linier,\nyaitu mengasumsikan bahwa variabel respons dapat dituliskan sebagai\nkombinasi linier dari variabel-variabel prediktornya. Beberapa alasan\nmengapa model linier ini paling umum dipakai adalah (Rawlings, Pantula, Dickey 1998): (1)\nmodel linier mudah dipahami; (2) beberapa model nonlinier secara\ninstrinsik linier, sehingga bisa didekati dengan pendekatan linier.Dalam banyak hal, variabel respons yang kita analisis \\(p>1\\), sehingga\npersamaan umum regresinya menjadi:\\[\\begin{equation} \ny_i=\\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + ... + \\beta_px_{ip} + \\epsilon_i\n\\tag{1.3}\n\\end{equation}\\]Model ini disebut sebagai model regresi linier berganda. Disebut\nberganda karena melibatkan lebih dari satu variabel\nprediktor.Contoh-contohnya:Seorang mahasiswa ingin menduga koefisien-koefisien dari sebuah\nmodel yang menghubungkan bobot tanaman vaskular-tanaman yang\nmemiliki jaringan khusus yaitu xilem dan floem untuk mengangkut\nunsur hara, air dan mineral ke seluruh bagian tanaman-dengan\nkandungan unsur hara dalam tanah, jumlah air yang diterima dan\njangka waktu tanaman terpapar sinar matahari.Kerja fisik (mengangkat, memutar, mendorong benda berat) tetap tidak\ndapat dihindari walaupun kita sudah mampu membuat alat-alat untuk\nmembantu pekerjaan. Kadang pekerjaan itu harus kita lakukan dalam\nkondisi yang tidak ergonomis. Cedera tulang punggung seringkali\nditemui pada pekerja di sektor ini. Seorang manajer produksi mungkin\ntertarik untuk mengurangi masalah cedera tulang belakang ini dengan\nmenginvestigasi hubungan kepadatan mineral tulang belakang dengan\nusia, berat dan tinggi badan, jenis kelamin dan gaya hidup pekerja.Seorang analis ingin mengetahui tingkat kepuasan karyawan sebuah\nperusahaan terhadap pekerjaannya. Skor total kepuasan kerja karyawan\ndihitung dari penjumlahan skor-skor 20 pertanyaan dengan menggunakan\n5 poin skala likert. Sedangkan prediktornya digunakan variabel\ndemografi meliputi usia, jenis kelamin dan pendidikan terakhir\nkaryawan.Di dalam teori konsumen, preferensi seorang konsumen terhadap suatu\nproduk dipengaruhi oleh pengetahuan konsumen terhadap produk,\nemosi,word mouth, faktor-faktor personal dan lingkungan.","code":"## The following objects are masked from PJMotor (pos = 7):\n## \n##     Tahun, x, y"},{"path":"pendahuluan.html","id":"asumsi-asumsi-model-linier","chapter":"1 Pendahuluan","heading":"1.2 Asumsi-Asumsi Model Linier","text":"models wrong, useful (Box 1979). Seperti\nhalnya metodologi statistik yang lain, analisis regresi linier dapat\nmenjadi cara yang sangat efektif untuk memodelkan data sepanjang\nasumsi-asumsinya terpenuhi. Jika asumsinya tidak terpenuhi, kuadrat\nterkecil berpotensi memberikan hasil yang arahnya tidak tepat\n(misleading).Setelah analisis regresi dilakukan, kita harus melakukan uji diagnostik:\nmemastikan apakah model memenuhi asumsi-asumsi model linier. Uji\ndiagnostik dapat dilakukan secara grafik maupun dengan uji formal.Asumsi-asumsi regresi linier adalah:Linieritas data: hubungan antara prediktor \\(x\\) dengan respons \\(y\\)\ndiasumsikan linier.Normalitas residu. error/residu diasumsikan terdistribusi secara\nnormal.Homogenitas variansi residu: residu diasumsikan mempunyai variansi\nyang tetap (homoskedastisitas)Independensi residu.Potensi-potensi tidak terpenuhinya asumsi model regresi adalah:Hubungan antara respons dengan prediktor tidak linierHeteroskedastisitas: variansi residu tidak tetap.Adanya nilai-nilai yang “berpengaruh” besar yang berasal dari ()\nnilai pencilan (outlier) yaitu nilai-nilai ekstrim pada variabel\nrespons; (b) high-leverage points: nilai-nilai ekstrim pada variabel\nprediktor.Setelah dilakukan uji diagnostik, maka uji-uji hipotesis, interval dan\nprediksi dapat dilakukan, karena uji-uji ini didasarkan atas kepercayaan\nbahwa asumsi-asumsi model regresi dipenuhi. Jadi penting sekali untuk\nmelakukan pengecekan terhadap asumsi-asumsi ini.","code":""},{"path":"pendahuluan.html","id":"uji-signifikansi","chapter":"1 Pendahuluan","heading":"1.3 Uji Signifikansi","text":"Salah satu fungsi dari regresi linier adalah untuk estimasi kondisi\npopulasi. Kita mengamati dan mengumpulkan data sampel, tetapi kita ingin\nmengetahui apakah data sampel yang kita miliki juga menerangkan sesuatu\ntentang populasi dimana data ini diambil. Dengan kata lain kita ingin\nmengetahui apakah hasil dari analisis data sampel dapat digeneralisasi\nke populasi dengan uji signifikansi.Uji signifikansi dapat dilakukan jika asumsi-asumsi model regresi telah\ndipenuhi. Uji-uji signifikansi itu antara lain:Uji t: digunakan untuk mengetahui apakah koefisien-koefisien regresi\nsecara statistik berbeda secara signifikan\n(statistically-significantly) dari nol.Uji t: digunakan untuk mengetahui apakah koefisien-koefisien regresi\nsecara statistik berbeda secara signifikan\n(statistically-significantly) dari nol.Uji F: jika uji t digunakan untuk menguji hanya satu koefisien, uji\nF digunakan untuk menguji lebih dari satu koefisien secara serempak.Uji F: jika uji t digunakan untuk menguji hanya satu koefisien, uji\nF digunakan untuk menguji lebih dari satu koefisien secara serempak.","code":""},{"path":"pendahuluan.html","id":"langkah-langkah-melakukan-analisis-regresi","chapter":"1 Pendahuluan","heading":"1.4 Langkah-langkah Melakukan Analisis Regresi","text":"Berdasarkan uraian sebelumnya, secara umum langkah-langkah dalam melakukan analisis regresi adalah sebagai berikut:Menentukan variabel respons \\(y\\) yang akan kita pelajari atau buat\nmodelnya.Menentukan sejumlah variabel prediktor yang kita anggap berguna di\ndalam menjelaskan variabel respons.Mengumpulkan data (sampel) yang dapat digunakan untuk menguji model.Mengestimasi model.Cek kecukupan model/uji diagnostik (jika hasilnya kurang memuaskan,\nkembali ke tahap 1).Uji signifikansi dan inferensial.Menulis hasil analisis.","code":""},{"path":"pendahuluan.html","id":"penggunaan-komputer","chapter":"1 Pendahuluan","heading":"1.5 Penggunaan Komputer","text":"Jika diperhatikan langkah-langkah untuk melakukan analisis regresi pada\n1.3, membangun model regresi merupakan sebuah proses iteratif. Dimulai\ndengan kajian teori yang berhubungan topik yang sedang diteliti dan\nketersediaan data untuk menentukan variabel respons dan variabel\neksplanatori untuk membangun model awal.Salah satu pertimbangan penting di dalam memilih variabel prediktor\nadalah apakah variabel tersebut dapat mengurangi variasi dalam variabel\nrespons. Pertimbangan lain adalah seberapa mudah, murah dan akurat data\nvariabel itu bisa diperoleh dibandingkan calon variabel prediktor yang\nlain. Pemilihan ini harus cermat karena bagaimanapun model adalah sebuah\npenyederhanaan dari realitas yang lebih kompleks, sehingga sebaiknya\nbeberapa prediktor saja dimasukkan ke dalam model.Menampilkan data dalam grafik atau diagram pencar seringkali sangat\nberguna untuk spesifikasi model awal. Setelah itu parameter-parameter\nmodel diestimasi. Setelah itu kecukupan model dievaluasi yang meliputi\nmencari kemungkinan terjadi kesalahan spesifikasi model, kemungkinan\ntidak memasukkan variabel penting atau memasukkan variabel yang tidak\nperlu, menemukan data pencilan (outlier).Kecukupan dan kecocokan model harus dicek karena menentukan apakah model\nyang dibuat dapat dipakai atau tidak. Hasil dari cek kecukupan mungkin\nmengindikasikan apakah model yang dibuat cukup masuk akal atau perlu\ndimodifikasi. Di dalam uji kecukupan terutama yang perlu dicek adalah\nresidu sebagai realisasi dari kesalahan model \\(\\epsilon\\).Jika model tidak cukup memenuhi, maka perlu dilakukan tindakan perbaikan\ndan pendugaan paramater diulang lagi. Proses ini mungkin perlu diulang\nbeberapa kali sampai diperoleh model yang memuaskan. Selanjutnya\ndilakukan validasi untuk memastikan bahwa model dapat diterima di dalam\ntahap akhir penerapannya.Dengan demikian, analisis regresi seringkali melibatkan banyak\npenghitungan, apalagi jika jumlah sampelnya besar dan variabel\nprediktornya banyak. Untuk membantu mempercepat proses ini kita menggunakan program komputer.Program komputer yang bagus adalah alat yang diperlukan dalam proses\nmembangun model. Tetapi program komputer saja belum cukup. Analisis\nregresi memerlukan seni dan inteligensia dalam penggunaan komputer.\nAnalis harus belajar bagaimana menginterpretasikan output komputer dan\nmengintegrasikan informasi yang didapat dengan model-model yang akan\ndibuat selanjutnya.Berbagai program statistik seperti SPSS, Stata, Minitab, Eviews, SAS,\nJMP, R, dan lain-lain dapat melakukan penghitungan regresi secara cepat\ndengan hasil yang kurang lebih sama. Di buku ini saya menggunakan\nsoftware R (R Core Team 2021) untuk membuat grafik maupun penghitungan\nregresinya.","code":""},{"path":"regresi-linier-sederhana.html","id":"regresi-linier-sederhana","chapter":"2 Regresi Linier Sederhana","heading":"2 Regresi Linier Sederhana","text":"Bab ini akan membahas regresi linier sederhana. Istilah regresi sederhana tidak merujuk pada kenaifan penelitiannya tetapi merujuk pada model yang hanya terdiri dari satu variabel respons dan satu variabel prediktor.Situasi ini sering terjadi pada penelitian sains. Misalnya seorang peneliti ingin memprediksi laju reaksi kimia karena perubahan temperatur, atau ingin mengetahui hubungan antara perubahan diet dengan tingkat kolesterol pada seseorang. Jika dapat diasumsikan bahwa variabel-variabel ini terhubung secara linier, kita dapat menggunakan regresi linier sederhana untuk mengkuantifikasi hubungan ini.Analisis regresi digunakan ketika solusi eksak tidak tersedia, dalam arti kita tidak akan dapat menemukan nilai tunggal yang dapat mencakup secara lengkap hubungan antara variabel respons dengan prediktornya. Sehingga disini kita mencoba memprediksi setepat mungkin variabel respons atau memprediksi dengan kesalahan terkecil.Untuk mencapai tujuan ini, kita menganalisis pola-pola variabilitas pada variabel respons dan mencoba melihat apakah variabilitas ini dapat diprediksi dari variabilitas prediktornya.","code":""},{"path":"regresi-linier-sederhana.html","id":"model-regresi-linier-sederhana","chapter":"2 Regresi Linier Sederhana","heading":"2.1 Model Regresi Linier Sederhana","text":"Model regresi linier sederhana dapat dituliskan sebagai berikut:\\[\\begin{equation} \ny_i=\\beta_0 + \\beta_1x_i+ \\epsilon_i\n\\tag{2.1}\n\\end{equation}\\]Regresi sederhana mengindikasikan hanya ada satu variabel prediktor x untuk menduga variabel respons y. Linier disini diartikan modelnya linier pada parameternya dalam hal ini \\(\\beta_0\\) dan \\(\\beta_1\\). Jadi model \\(y_i = \\beta_0 + \\beta_1{x_i}^2 + \\epsilon_i\\) adalah linier pada \\(\\beta_0\\) dan \\(\\beta_1\\), sementara model \\(y_i = \\beta_0 + e^{\\beta_ix_i} + \\epsilon_i\\) tidak linier.Misalkan kita memiliki pasangan-pasangan data sampel sebanyak n yang diambil secara acak dari populasi yang lebih besar \\((x_1,y_1), (x_2,y_2), ⋯, (x_n,y_n)\\). Tujuan dari analisis regresi linier adalah menemukan model terbaik yaitu menemukan nilai \\(\\beta_0\\) \\(\\beta_1\\) yang menghasilkan garis paling cocok dengan titik-titik data yang kita punyai.Dengan kata lain tujuan dari analisis regresi adalah mengestimasi koefisien regresi untuk variabel prediktor sehingga didapatkan nilai dugaan variabel respons sedekat mungkin nilainya dengan nilai pengamatan aktualnya.Di dalam analisis regresi, model terbaik ditunjukkan oleh garis lurus yang menghubungkan rata-rata variabel prediktor dengan variabel respons sedemikian rupa sehingga jumlah kuadrat kesalahan (jarak vertikal antara titik-titik data pengamatan aktual \\(y_i\\) dengan nilai dugaannya \\(\\hat y_i\\)) minimal.Untuk memperoleh nilai dugaan \\(\\beta_0\\) dan \\(\\beta_1\\) yang paling cocok, kita menggunakan metode kuadrat terkecil (method least squares). Dengan pendekatan kuadrat terkecil, kita mencari nilai dugaan \\(\\beta_0\\) dan \\(\\beta_1\\) yang meminimalkan jumlah kuadrat residu/kesalahan (\\(y_i-\\hat y_i\\)).","code":""},{"path":"regresi-linier-sederhana.html","id":"kasus-1-penjualan-motor-dan-pertumbuhan-pendapatan-perkapita","chapter":"2 Regresi Linier Sederhana","heading":"2.1.1 Kasus 1: Penjualan Motor dan Pertumbuhan Pendapatan Perkapita","text":"Kita akan melanjutkan kasus hubungan antara penjualan motor dengan pendapatan pada Bab 1 sebelumnya sebagai ilustrasi regresi linier sederhana. Data dapat diunduh di sini. Langkah awal untuk melihat bagaimana hubungan antar variabel adalah membuat diagram pencar.Plot sangat penting di dalam regresi. Pemeriksaan diagram pencar secara teliti harus mendahului penghitungan regresi. Diagram pencar dapat mengindikasikan apakah model regresi yang diinginkan mungkin masuk akal atau tidak. Kesepakatan dalam membuat diagram pencar, variabel \\(x\\) sebagai variabel penjelas diplot pada sumbu horisontal. Varibel \\(y\\) sebagai variabel respons diplot pada sumbu vertikal.Untuk membuat diagram pencar, hal pertama yang harus dilakukan adalah memasukkan data ke dalam R, mengecek apakah data yang kita masukkan sudah betul dan memanggil library yang relevan dengan model yang akan dibuat.Perintah plot(x,y) di dalam R adalah untuk membuat plot antara variabel respons dengan variabel prediktor. Hasilnya ditampilkan pada Gambar 2.1.Di dalam R model regresi linier sederhana dapat diperoleh dengan perintah lm(y~x). Tanda ~ dapat diartikan \\(y\\) dijelaskan oleh \\(x\\). Fungsi ini mengestimasi koefisien regresi model linier dengan metode kuadrat terkecil (least squares method).Semisal modelnya kita beri nama model penjualan motor (mpm), yang memodelkan hubungan antara penjualan motor (\\(y\\)) dengan pertumbuhan pendapatan (\\(x\\)), maka model ini dapat diperoleh dengan perintah:Perintah ini sama dengan persamaan dibawah:\\[ y = β_0 + β_1x + ε \\]Kita kemudian menggunakan perintah summary() untuk menampilkan luarannya. Hasilnya adalah sebagai berikut:Hasil regresi menunjukkan nilai dugaan intersep garis regresi \\(\\hat \\beta_0\\) = -1.210 (SE= 2.088), p-value = 0.57 (tidak signifikan). Sedangkan nilai dugaan \\(\\hat \\beta_1\\) = 1.733 (SE = 0.525) dan p-valuenya (menguji hipotesis nol bahwa \\(\\beta_1\\) = 0) kecil, konsisten dengan bukti persebaran data yang cenderung linier.Di dalam R, kita bisa dengan mudah menambahkan nilai-nilai dugaan dan residu ke dalam data dengan menggunakan perintah augment() dari broom package. Misalkan outputnya kita sebut sebagai uji.diagnostik (dibahas secara lebih lengkap di Bab 4).Kolom-kolom pada tabel diatas menunjukkanKode berikut memplot residuals error (warna merah) yaitu selisih antara nilai pengamatan dengan nilai dugaan. Setiap garis vertikal warna merah menunjukkan nilai kesalahan/residu antara angka penjualan motor aktual dengan nilai dugaannya.Diagram pencar dan garis regresi juga dapat dapat ditampilkan bersama-sama dengan perintah berikut:Koefisisen determinasi (\\(R^2\\)) sebesar 39 persen. Artinya model kita hanya menjelaskan sebesar 39 persen variasi pada penjualan motor. Cukup masuk akal karena model kita hanya menggunakan satu variabel penjelas yaitu pertumbuhan per kapita.work progress…sedang dalam proses pengerjaan","code":"\n# memanggil data dalam bentuk teks ke dalam R\nPJMotor <- read.delim(\"PJMotor.txt\") \nPJMotor <- as.data.frame(PJMotor)\n# untuk melihat beberapa baris data teratas\nhead(PJMotor) ##   Tahun        y        x\n## 1  2001 1.575822 2.235180\n## 2  2002 2.287706 3.090636\n## 3  2003 2.809896 3.376533\n## 4  2004 3.887678 3.630909\n## 5  2005 5.074186 4.289591\n## 6  2006 4.428274 4.107514\n# untuk melihat beberapa baris data terakhir\ntail(PJMotor) ##    Tahun        y        x\n## 14  2014 7.867195 3.639072\n## 15  2015 6.480155 3.555062\n## 16  2016 5.931285 3.758837\n## 17  2017 5.886103 3.841197\n## 18  2018 6.383108 3.987825\n## 19  2019 6.487460 3.871444\n#membuat diagram pencar\nplot(x,y) \nmpm <- lm(y ~ x)\n# Perhatikan tanda panah ke kiri. \n# Intersep dan slope secara default diestimasi. \n# Bandingkan dengan perintah untuk mendapatkan diagram pencar. \n# perintah summary() untuk mengekstrak hasil regresi\nsummary (mpm) ## \n## Call:\n## lm(formula = y ~ x)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -2.6738 -1.1721  0.2916  0.9911  2.7707 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)   \n## (Intercept)   -1.210      2.088  -0.579  0.56999   \n## x              1.733      0.525   3.301  0.00422 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.515 on 17 degrees of freedom\n## Multiple R-squared:  0.3906, Adjusted R-squared:  0.3547 \n## F-statistic: 10.89 on 1 and 17 DF,  p-value: 0.004224\n# menambahkan nilai-nilai dugaan dan residu\nlibrary(\"broom\")\nuji.diagnostik <- augment(mpm)\nhead(uji.diagnostik)## # A tibble: 6 x 8\n##       y     x .fitted .resid   .hat .sigma .cooksd .std.resid\n##   <dbl> <dbl>   <dbl>  <dbl>  <dbl>  <dbl>   <dbl>      <dbl>\n## 1  1.58  2.24    2.66  -1.09 0.394    1.52  0.277      -0.922\n## 2  2.29  3.09    4.15  -1.86 0.136    1.48  0.136      -1.32 \n## 3  2.81  3.38    4.64  -1.83 0.0883   1.49  0.0776     -1.27 \n## 4  3.89  3.63    5.08  -1.19 0.0628   1.53  0.0222     -0.814\n## 5  5.07  4.29    6.22  -1.15 0.0689   1.53  0.0228     -0.786\n## 6  4.43  4.11    5.91  -1.48 0.0568   1.51  0.0304     -1.01x: pertumbuhan pendapatan per kapita\ny: penjualan motor\n.fitted: nilai dugaan penjualan motor\n.resid: the residual errors\nlibrary(ggplot2)\nmy.formula <- y ~ x\nggplot(uji.diagnostik, aes(x, y)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = FALSE, formula = my.formula, size = 0.8) +\n  geom_segment(aes(xend = x, yend = .fitted), color = \"red\", size = 0.4, linetype = \"dashed\")\nlibrary(ggpmisc)\nPJMotor <- as.data.frame(PJMotor)\nmy.formula <- y ~ x\nggplot(data = PJMotor, aes(x = x, y = y)) +\n   geom_smooth(method = \"lm\", se=FALSE, color=\"blue\", size = 0.8, formula = my.formula) +\n   stat_poly_eq(formula = my.formula,\n                eq.with.lhs = \"italic(hat(y))~`=`~\",\n                aes(label = paste(..eq.label.., ..rr.label.., sep = \"~~~\")), \n                parse = TRUE) +         \n   geom_point()"},{"path":"regresi-linier-berganda.html","id":"regresi-linier-berganda","chapter":"3 Regresi Linier Berganda","heading":"3 Regresi Linier Berganda","text":"Pengembangan regresi linier sederhana adalah regresi linier berganda (multiple linear regression). Dengan regresi linier berganda, kita dapat memasukkan lebih dari satu variabel penjelas ke dalam model karena di dalam praktik model yang kita pakai kemungkinan lebih kompleks dari model regresi linier sederhana.Pengembangan ini berguna dari dua sisi. Pertama, penambahan variabel penjelas dapat memberikan penjelasan yang lebih lengkap tentang variabel respons, karena jarang suatu fenomena hanya disebabkan oleh satu hal. Kedua, dampak dari variabel prediktor tertentu dibuat lebih terang, karena kemungkinan dampak distorsi dari variabel prediktoryang lain dihilangkan.Jika kita sudah memahami dasar-dasar dari regresi linier sederhana, kita dapat mengembangkannya untuk melakukan analisis yang lebih rumit dengan bantuan program komputer. Estimasi dan interpretasi parameter mengikuti prinsip-prinsip yang sama. Begitu juga dengan uji signifikansi, koefisien determinasi (\\(R^2\\)) dan asumsi-asumsi pada regresi linier sederhana terus dibawa ke dalam regresi linier berganda.Hal-hal yang harus diperhatikan karena berpotensi menjadi masalah dalam melakukan analisis regresi adalah isu-isu yang berhubungan (1) overfitting, (2) heteroskedastisitas, (3) multikolinearitas. Teknik regresi berganda sangat luas cakupannya. Penguasaan teknik regresi berganda akan memberikan bekal yang sangat berharga untuk menganalisis banyak jenis data kuantitatif.","code":""},{"path":"regresi-linier-berganda.html","id":"persamaan-umum","chapter":"3 Regresi Linier Berganda","heading":"3.1 Persamaan Umum","text":"Secara umum, di dalam persamaan regresi berganda variabel respons dipandang sebagai fungsi linier dari lebih dari satu variabel prediktor \\(1>p\\).\\[\\begin{equation} \ny_i=\\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + ... + \\beta_px_{ip} + \\epsilon_i\n\\tag{3.1}\n\\end{equation}\\]Untuk model dengan dua variabel prediktor, persamaannya dapat dituliskan sebagai:\\[\\begin{equation} \ny_i=\\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\epsilon_i\n\\tag{3.2}\n\\end{equation}\\]yang menunjukkan bahwa y ditentukan oleh \\(x1\\) dan \\(x2\\), ditambah faktor kesalahan. Untuk mengestimasi nilai-nilai parameter, kita gunakan prinsip kuadrat kesalahan terkecil (least squares principle), dengan meminimalkan jumlah kuadrat kesalahan prediksi (SSE):\\[\\begin{equation}\nSSE = \\Sigma(y - \\hat y)^2\n\\tag{3.3}\n\\end{equation}\\]Koefisien-koefisien yang diperoleh dari prinsip ini (\\(\\beta_0, \\beta_1, \\beta_2\\)) menghasilkan kesalahan prediksi paling kecil dibandingkan kombinasi-kombinasi koefisien yang lain.\nTetapi disini kita tidak bisa lagi menampilkan diagram pencar dengan garis lurus pada bidang dua dimensi.Kita harus menampilkan perpencaran datanya pada bidang tiga dimensi. Lokasi dari garis pada bidan tiga dimensi ini ditentukan oleh besaran nilai-nilai-nilai (\\(\\beta_0, \\beta_1, \\beta_2\\)). Jika variabel penjelasnya lebih dari tiga, perpencaran datanya tidak mungkin untuk digambarkan.sedang dalam proses pengerjaan (work progress…)","code":""},{"path":"uji-diagnostik-dan-tindakan-perbaikan.html","id":"uji-diagnostik-dan-tindakan-perbaikan","chapter":"4 Uji Diagnostik dan Tindakan Perbaikan","heading":"4 Uji Diagnostik dan Tindakan Perbaikan","text":"Di dalam analisis regresi, kriteria jumlah kuadrat terkecil tidak akan memberikan hasil yang memuaskan kecuali asumsi-asumsinya dipenuhi. Sampai saat ini kita belum melakukan uji asumsi-asumsi OLS. Uji diagnostik digunakan untuk melihat apakah asumsi-asumsi model dipenuhi atau terjadi pelanggaran pada asumsi-asumsi tersebut. Uji diagnostik biasanya menggunakan nilai residu.Di bab ini kita akan menggunakan alat-alat yang dapat digunakan untuk mengidentifikasi dan mengatasi permasalahan-permasalahan yang biasa ditemui dalam penerapan metode kuadrat terkecil di dalam analisis regresi. Kita akan menggunakan baik grafik maupun rumus-rumus di dalam uji diagnostik ini.","code":""},{"path":"uji-diagnostik-dan-tindakan-perbaikan.html","id":"uji-asumsi-dengan-plotting-nilai-residu","chapter":"4 Uji Diagnostik dan Tindakan Perbaikan","heading":"4.1 Uji Asumsi dengan Plotting Nilai Residu","text":"Hanya dengan melihat beberapa plot nilai residu bukti-bukti pemenuhan/pelanggaran asumsi OLS bisa kita dapatkan. Hal ini menjadi keunggulan uji diagnostik menggunakan plot: sangat fleksibel. Hasil plot dapat menunjukkan bukti-bukti pelanggaran asumsi-asumsi dan tidak memerlukan spesifikasi pasti bentuk pelanggarannya. Fleksibilitas cara ini, selain menjadi keunggulan sekaligus menjadi kelemahannya. Cara ini bersifat subjektif, sehingga orang berbeda bisa mempunyai pandangan yang berbeda pula mengenai validitas asumsi-asumsinya. Selain itu plot hanya bisa memberikan “pandangan” dua dimensi dari regresi berganda.Beberapa plot untuk menguji asumsi OLS:Plot residu dengan nilai dugaan.Plot residu dengan masing-masing prediktor.Plot residu dengan waktu untuk data yang mengandung struktur waktu.Plot normal residu.","code":""},{"path":"uji-diagnostik-dan-tindakan-perbaikan.html","id":"uji-asumsi-dengan-tes-statistik","chapter":"4 Uji Diagnostik dan Tindakan Perbaikan","heading":"4.2 Uji Asumsi dengan Tes Statistik","text":"sedang dalam proses pengerjaan (work progress…)","code":""},{"path":"model-regresi-linier-lanjutan.html","id":"model-regresi-linier-lanjutan","chapter":"5 Model Regresi Linier Lanjutan","heading":"5 Model Regresi Linier Lanjutan","text":"Ketika terjadi perubahan pada kuantitas sebuah variabel yang ada di dalam sebuah sistem, kita biasanya ingin tahu dampak dari perubahan itu terhadap variabel-variabel lain yang ada di sistem tersebut. Hubungan ini mungkin dapat dimodelkan dengan hubungan fungsional sederhana. Bisa jadi juga hubungan ini lebih kompleks sehingga hubungan fungsional sederhana harus dikembangkan. Model linier adalah salah alat penting untuk menganalisis hal ini.Persamaan umum model regresi dengan variabel respons \\(y\\) dan prediktor x sebanyak \\(p\\): \\(x_1, x_2, ... , x_p\\) adalah:\\[\\begin{equation}\ny = \\beta_0 + \\beta_1x_1 + ... + \\beta_px_p + \\epsilon\n\\tag{5.1}\n\\end{equation}\\]dimana \\(\\epsilon\\) terdistribusi secara normal. Persamaan di atas dapat dikembangkan berdasarkan tiga bagian penyusunnya. Bagian pertama adalah \\(y\\), kedua adalah \\(\\epsilon\\), dan ketiga adalah \\(x\\):Generalized Linear Models (GLM): Model linier standard tidak dapat mengakomodasi variabel respons \\(y\\) yang tidak normal seperti data dalam bentuk proporsi, persentase, binari, kategori dan count. Jika variabel respons seperti ini kita gunakan generalized linear model.Generalized Linear Models (GLM): Model linier standard tidak dapat mengakomodasi variabel respons \\(y\\) yang tidak normal seperti data dalam bentuk proporsi, persentase, binari, kategori dan count. Jika variabel respons seperti ini kita gunakan generalized linear model.Mixed Effect Model: Model ini kita gunakan jika data kita tersusun secara hierarkis atau berkelompok. Misal untuk data pengamatan berulang, longitudinal dan data berjenjang yang mengakibatkan suatu struktur korelasi pada komponen errornya \\(\\epsilon\\).Mixed Effect Model: Model ini kita gunakan jika data kita tersusun secara hierarkis atau berkelompok. Misal untuk data pengamatan berulang, longitudinal dan data berjenjang yang mengakibatkan suatu struktur korelasi pada komponen errornya \\(\\epsilon\\).Model Regresi Nonparametrik (Nonparametric Regression Model): Pada model linier, variabel prediktor \\(x\\) dikombinasikan secara linier untuk memodelkan dampaknya pada variabel respons. Akan tetapi kadang kala, linieritas ini tidak cukup menangkap struktur data sehingga diperlukan fleksibilitas lebih. Metode-metode yang dapat mengakomodasi ini misalnya additive model, trees neural networks memungkinkan pemodelan yang lebih fleksibel pada respons yang mengkombinasikan prediktor secara nonparametrik.Model Regresi Nonparametrik (Nonparametric Regression Model): Pada model linier, variabel prediktor \\(x\\) dikombinasikan secara linier untuk memodelkan dampaknya pada variabel respons. Akan tetapi kadang kala, linieritas ini tidak cukup menangkap struktur data sehingga diperlukan fleksibilitas lebih. Metode-metode yang dapat mengakomodasi ini misalnya additive model, trees neural networks memungkinkan pemodelan yang lebih fleksibel pada respons yang mengkombinasikan prediktor secara nonparametrik.","code":""},{"path":"model-regresi-linier-lanjutan.html","id":"generalized-linear-models-glm","chapter":"5 Model Regresi Linier Lanjutan","heading":"5.1 Generalized Linear Models (GLM)","text":"","code":""},{"path":"model-regresi-linier-lanjutan.html","id":"mixed-effect-model","chapter":"5 Model Regresi Linier Lanjutan","heading":"5.2 Mixed Effect Model","text":"","code":""},{"path":"model-regresi-linier-lanjutan.html","id":"model-regresi-nonparametrik","chapter":"5 Model Regresi Linier Lanjutan","heading":"5.3 Model Regresi Nonparametrik","text":"sedang dalam proses pengerjaan (work progress…)","code":""},{"path":"referensi.html","id":"referensi","chapter":"Referensi","heading":"Referensi","text":"","code":""}]
